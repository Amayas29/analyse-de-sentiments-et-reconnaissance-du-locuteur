{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de présidents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = stopwords.words(\"french\")\n",
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s = codecs.open(fname, 'r', 'utf-8')  # pour régler le codage\n",
    "\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if (len(txt)) < 5:\n",
    "            break\n",
    "\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\", \"\\\\1\", txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\", \"\\\\1\", txt)\n",
    "\n",
    "        if lab.count('M') > 0:\n",
    "            alllabs.append(-1)\n",
    "        else:\n",
    "            alllabs.append(1)\n",
    "\n",
    "        alltxts.append(txt)\n",
    "\n",
    "    return np.array(alltxts), np.array(alllabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts, alllabs = load_pres(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts), len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(alllabs)  # nos labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Transformation paramétrique du texte (pre-traitements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train/Test split des données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(alltxts))\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    alltxts, alllabs, stratify=alllabs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Appliquer une lemmatisation sur la base d'entrainement (Pour des questions d'optimisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    docs = list(nlp.pipe(tokens, disable=[\"parser\", \"ner\"]))\n",
    "    tokens_lem = [doc[0].lemma_ for doc in docs]\n",
    "    text = ' '.join(tokens_lem)\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize_data(data):\n",
    "    lemmatize_text_vec = np.vectorize(lemmatize_text)\n",
    "    data_lem = lemmatize_text_vec(data)\n",
    "    return data_lem\n",
    "\n",
    "\n",
    "if \"Xtrain_lem\" not in globals():\n",
    "    Xtrain_lem = lemmatize_data(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_strat(text, X):\n",
    "\n",
    "    punc = string.punctuation\n",
    "    punc += '\\n\\r\\t'\n",
    "    text = text.translate(str.maketrans(punc, ' ' * len(punc)))\n",
    "\n",
    "    text = unicodedata.normalize('NFD', text).encode(\n",
    "        'ascii', 'ignore').decode(\"utf-8\")\n",
    "    text = re.sub('(www|http)[\\w\\.-_]+\\.(fr|com|org)', 'URL', text)\n",
    "\n",
    "    if X[\"ToLower\"]:\n",
    "        text = text.lower()\n",
    "\n",
    "    if X[\"DeleteNumbers\"]:\n",
    "        text = re.sub('[0-9]+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def fit(X, force_count_vec=False):\n",
    "    preprocess = None\n",
    "    stopwords = None\n",
    "    ngram_range = (1, 1)\n",
    "    use_idf = True\n",
    "    min_df = 1\n",
    "    max_df = 1.0\n",
    "    max_features = None\n",
    "    binary = False\n",
    "    data = Xtrain\n",
    "    count_vec = True\n",
    "\n",
    "    if X is not None:\n",
    "        def preprocess(text): return preprocess_strat(text, X)\n",
    "\n",
    "        if \"stopwords\" in X:\n",
    "            stopwords = X[\"stopwords\"]\n",
    "        if \"ngram_range\" in X:\n",
    "            ngram_range = X[\"ngram_range\"]\n",
    "        if \"use_idf\" in X:\n",
    "            use_idf = X[\"use_idf\"]\n",
    "        if \"min_df\" in X:\n",
    "            min_df = X[\"min_df\"]\n",
    "        if \"max_df\" in X:\n",
    "            max_df = X[\"max_df\"]\n",
    "        if \"max_features\" in X:\n",
    "            max_features = X[\"max_features\"]\n",
    "        if \"binary\" in X:\n",
    "            binary = X[\"binary\"]\n",
    "        if \"lemmatized\" in X and X[\"lemmatized\"]:\n",
    "            data = Xtrain_lem\n",
    "        \n",
    "        if not force_count_vec and \"count_vec\" in X:\n",
    "            count_vec = X[\"count_vec\"]\n",
    "\n",
    "    if count_vec:\n",
    "        vectorizer = CountVectorizer(\n",
    "            preprocessor=preprocess, stop_words=stopwords)\n",
    "        return vectorizer.fit_transform(data), vectorizer\n",
    "\n",
    "    vectorizer = TfidfVectorizer(preprocessor=preprocess, stop_words=stopwords, ngram_range=ngram_range, use_idf=use_idf,\n",
    "                                 min_df=min_df, max_df=max_df, max_features=max_features, binary=binary)\n",
    "\n",
    "    return vectorizer.fit_transform(data), vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = {\n",
    "    \"name\": \"Lower | Not Number | Stop Words\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strats = [X1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "- **Exploration préliminaire des jeux de données**\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base, vectorizer = fit(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la taille d'origine du vocabulaire?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordcloud(X, count_vec, odd_ratio=False):\n",
    "\n",
    "    vectors, vectorizer = fit(X, force_count_vec=count_vec)\n",
    "\n",
    "    if not odd_ratio:\n",
    "        counts = np.array(vectors.sum(axis=0))[0]\n",
    "    else:\n",
    "        # Classe 1\n",
    "        p = np.array(vectors[ytrain == 1].sum(axis=0))[0]\n",
    "        # Classe -1\n",
    "        q = np.array(vectors[ytrain == -1].sum(axis=0))[0]\n",
    "\n",
    "        odds1 = p * (1 - q)\n",
    "        odds2 = q * (1 - p)\n",
    "\n",
    "        odds_ratio = np.where(odds2 == 0, 0, odds1 / odds2)\n",
    "\n",
    "    dico = dict()\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        if not odd_ratio:\n",
    "            dico[w] = counts[i]\n",
    "        else:\n",
    "            dico[w] = odds_ratio[i]\n",
    "\n",
    "    return WordCloud(background_color='white', stopwords=[],\n",
    "                     max_words=100).generate_from_frequencies(dico)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(strats)+1, figsize=(20, 5))\n",
    "\n",
    "wordcloud = get_wordcloud(None, count_vec=True)\n",
    "axs[0].imshow(wordcloud)\n",
    "axs[0].set_title('Vocabulaire initiale')\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "for i, X in enumerate(strats):\n",
    "    wordcloud = get_wordcloud(X, count_vec=True)\n",
    "    axs[i+1].imshow(wordcloud)\n",
    "    axs[i+1].set_title(X[\"name\"])\n",
    "    axs[i+1].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Wordcloud des 100 mots les plus fréquents dans deux vocabulaires\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(strats)+1, figsize=(20, 5))\n",
    "\n",
    "wordcloud = get_wordcloud(None, count_vec=False)\n",
    "axs[0].imshow(wordcloud)\n",
    "axs[0].set_title('Vocabulaire initiale')\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "for i, X in enumerate(strats):\n",
    "    wordcloud = get_wordcloud(X, count_vec=False)\n",
    "    axs[i+1].imshow(wordcloud)\n",
    "    axs[i+1].set_title(X[\"name\"])\n",
    "    axs[i+1].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Wordcloud des 100 mots dont le Idf est max dans deux vocabulaires\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(strats)+1, figsize=(20, 5))\n",
    "\n",
    "wordcloud = get_wordcloud(None, count_vec=True, odd_ratio=True)\n",
    "axs[0].imshow(wordcloud)\n",
    "axs[0].set_title('Vocabulaire initiale')\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "for i, X in enumerate(strats):\n",
    "    wordcloud = get_wordcloud(X, count_vec=True, odd_ratio=True)\n",
    "    axs[i+1].imshow(wordcloud)\n",
    "    axs[i+1].set_title(X[\"name\"])\n",
    "    axs[i+1].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Wordcloud des 100 mots les plus discriminants au sens de odds ratio dans deux vocabulaires\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la distribution d'apparition des mots (Zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(strats)+1, figsize=(20, 5))\n",
    "\n",
    "vectors, vectorizer = fit(None, force_count_vec=True)\n",
    "counts = np.array(vectors.sum(axis=0))[0]\n",
    "index = counts.argsort()[::-1]\n",
    "axs[0].plot(counts[index])\n",
    "axs[0].set_title('Vocabulaire initiale')\n",
    "axs[0].set_xticklabels(vectorizer.get_feature_names_out(), rotation=90)\n",
    "\n",
    "for i, X in enumerate(strats):\n",
    "    vectors, vectorizer = fit(X, force_count_vec=True)\n",
    "    counts = np.array(vectors.sum(axis=0))[0]\n",
    "    index = counts.argsort()[::-1]\n",
    "    axs[i+1].plot(counts[index])\n",
    "    axs[i+1].set_title(X[\"name\"])\n",
    "    axs[i+1].set_xticklabels(vectorizer.get_feature_names_out(), rotation=90)\n",
    "\n",
    "plt.suptitle(\"Distibution d'apparition des mots dans deux vocabularies\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les 100 bigrammes/trigrammes les plus fréquents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bi = {\n",
    "    \"name\": \"Lower | Not Number | Stop Words | Bi-gram\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"ngram_range\": (2, 2),\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "}\n",
    "\n",
    "X_tri = {\n",
    "    \"name\": \"Lower | Not Number | Stop Words | Tri-gram\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"ngram_range\": (3, 3),\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "for i, X in enumerate([X_bi, X_tri]):\n",
    "    wordcloud = get_wordcloud(X, count_vec=False)\n",
    "    axs[i].imshow(wordcloud)\n",
    "    axs[i].set_title(X[\"name\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Variantes de BoW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strats = []\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | TF\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"use_idf\": False,\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "})\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | TF\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": True,\n",
    "})\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | min_max_df\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"min_df\": 10,\n",
    "    \"max_df\": 0.93,\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "})\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | min_max_df\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"min_df\": 6,\n",
    "    \"max_df\": 0.95,\n",
    "    \"lemmatized\": True,\n",
    "    \"max_features\": 10000,\n",
    "    \"count_vec\": False,\n",
    "})\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | Binary\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"binary\": True,\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "})\n",
    "\n",
    "strats.append({\n",
    "    \"name\": \"Lower | Not Number | Stop Words | Bi-gram\",\n",
    "    \"ToLower\": True,\n",
    "    \"DeleteNumbers\": True,\n",
    "    \"stopwords\": STOP_WORDS,\n",
    "    \"ngram_range\": (2, 2),\n",
    "    \"lemmatized\": True,\n",
    "    \"count_vec\": False,\n",
    "    \"min_df\": 7,\n",
    "    \"max_df\": 0.95,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in strats:\n",
    "    vectors, vectorizer = fit(X)\n",
    "    X[\"base\"] = vectors\n",
    "    X[\"vectorizer\"] = vectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(labels, y_hat):\n",
    "    scores = {}\n",
    "    scores[\"f1_score\"] = f1_score(labels, y_hat)\n",
    "    scores[\"accuracy\"] = accuracy_score(labels, y_hat)\n",
    "    scores[\"auc_roc\"] = roc_auc_score(labels, y_hat)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Xtest_lem\" not in globals():\n",
    "    Xtest_lem = lemmatize_data(Xtest)\n",
    "\n",
    "Xtest_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_strats(lstrats, optimizer, model_name, sample, scoring=\"f1_macro\"):\n",
    "    \n",
    "    if sample is not None:\n",
    "            model_name = f\"{model_name}_{sample}\"\n",
    "            \n",
    "    for X in tqdm(lstrats):            \n",
    "        X[model_name] = optimizer(X, scoring=scoring, sample=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(lstrats, model_name, sample):\n",
    "    \n",
    "    if sample is not None:\n",
    "        model_name = f\"{model_name}_{sample}\"\n",
    "        \n",
    "    for X in tqdm(lstrats):\n",
    "        Xtest_tran = X[\"vectorizer\"].transform(Xtest_lem)\n",
    "        y_hat = X[model_name].predict(Xtest_tran)\n",
    "        X[f\"scores_{model_name}\"] = eval_model(ytest, y_hat)\n",
    "        precision, recall, _, _ = precision_recall_fscore_support(ytest, y_hat)\n",
    "        X[f\"precision_{model_name}\"] = precision\n",
    "        X[f\"recall_{model_name}\"] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lineplot(scores, ax, score_name):\n",
    "    sns.lineplot(x=list(range(1, len(scores)+1)),\n",
    "                y=scores, color='steelblue', ax=ax, linestyle='--', marker='o')\n",
    "    \n",
    "    ax.set_xlabel('Numéro de la strategie')\n",
    "    ax.set_ylabel(score_name)\n",
    "    ax.set_title(f'Distribution des scores {score_name}')\n",
    "\n",
    "def optimization_report(lstrats, model_name, sample):\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    if sample is not None:\n",
    "        model_name = f\"{model_name}_{sample}\"\n",
    "        \n",
    "    scores_names = f\"scores_{model_name}\"\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=len(lstrats), ncols=2, figsize=(12, 30))\n",
    "\n",
    "    for i, X in enumerate(lstrats):\n",
    "        f1_scores.append(X[scores_names]['f1_score'])\n",
    "        accuracy_scores.append(X[scores_names]['accuracy'])\n",
    "        roc_auc_scores.append(X[scores_names]['auc_roc'])\n",
    "        \n",
    "        \n",
    "        axes[i, 0].bar([0, 1], X[f\"precision_{model_name}\"], align='center')\n",
    "        axes[i, 0].set_xticks([0, 1])\n",
    "        axes[i, 0].set_ylabel('Precision')\n",
    "        axes[i, 0].set_title('Precision by class')\n",
    "        \n",
    "        axes[i, 1].bar([0, 1], X[f\"recall_{model_name}\"], align='center')\n",
    "        axes[i, 1].set_xticks([0, 1])\n",
    "        axes[i, 1].set_ylabel('Recall')\n",
    "        axes[i, 1].set_title('Recall by class')\n",
    "        \n",
    "        axes[i, 0].grid(True, alpha=0.5)\n",
    "        axes[i, 1].grid(True, alpha=0.5)\n",
    "        \n",
    "        axes[i, 0].set_axisbelow(True)\n",
    "        axes[i, 1].set_axisbelow(True)\n",
    "        \n",
    "        fig.tight_layout(pad=3.0)\n",
    "        \n",
    "        axes[i, 0].annotate(f\"Strategie {i+1}\", xy=(0.5, 1), xytext=(0, 10), \n",
    "                            xycoords='axes fraction', textcoords='offset points', \n",
    "                            size='large', ha='center', va='baseline')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    lineplot(f1_scores, axs[0], \"F1 score\")\n",
    "    lineplot(accuracy_scores, axs[1], \"Accuracy\")\n",
    "    lineplot(roc_auc_scores, axs[2], \"AUC-ROC\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reglog_optimizer(X, sample, scoring='f1_macro'):\n",
    "    reglog = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "    params = {'C': [0.01, 0.1, 0.5, 1, 2], 'penalty': ['l2', None]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    grid = GridSearchCV(reglog, params, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "    \n",
    "    if sample is None:\n",
    "        grid.fit(X[\"base\"], ytrain)\n",
    "    else:\n",
    "        grid.fit(X[f\"X_{sample}\"], X[f\"y_{sample}\"])\n",
    "        \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, reglog_optimizer, \"reglog\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(strats, \"reglog\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_report(strats, \"reglog\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_optimizer(X, sample, n_estimators=100, scoring='f1_macro'):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, class_weight='balanced')\n",
    "    params = {'max_depth': [5, 7, 12], 'min_samples_split': [5, 10, 20, 30]}\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    grid = RandomizedSearchCV(rf, params, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "    \n",
    "    if sample is None:\n",
    "        grid.fit(X[\"base\"], ytrain)\n",
    "    else:\n",
    "        grid.fit(X[f\"X_{sample}\"], X[f\"y_{sample}\"])\n",
    "        \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, rf_optimizer, \"rf\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(strats, \"rf\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_report(strats, \"rf\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnb_optimizer(X, sample, scoring=None):\n",
    "    bnb = BernoulliNB()\n",
    "        \n",
    "    if sample is None:\n",
    "        bnb.fit(X[\"base\"], ytrain)\n",
    "    else:\n",
    "        bnb.fit(X[f\"X_{sample}\"], X[f\"y_{sample}\"])\n",
    "        \n",
    "    return bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, bnb_optimizer, \"bnb\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(strats, \"bnb\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_report(strats, \"bnb\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_optimizer(X, sample, scoring=\"f1_macro\"):\n",
    "    svm = LinearSVC(class_weight='balanced', max_iter=4000)\n",
    "    params = {'C': [0.001, 0.1, 0.5, 1, 1.5], 'penalty': [\"l1\", \"l2\"]}\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "    grid = RandomizedSearchCV(svm, params, cv=cv, n_jobs=-1, scoring=scoring)\n",
    "        \n",
    "    if sample is None:\n",
    "        grid.fit(X[\"base\"], ytrain)\n",
    "    else:\n",
    "        grid.fit(X[f\"X_{sample}\"], X[f\"y_{sample}\"])\n",
    "    \n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, svm_optimizer, \"svm\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(strats, \"svm\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_report(strats, \"svm\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage des classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec un échantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in tqdm(strats):\n",
    "    undersample = RandomUnderSampler()\n",
    "    D = X[\"base\"]\n",
    "    X_sample, y_sample = undersample.fit_resample(D, ytrain)\n",
    "    \n",
    "    X[\"X_under\"] = X_sample\n",
    "    X[\"y_under\"] = y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, reglog_optimizer, \"reglog\", \"under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(strats, \"reglog\", \"under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_report(strats, \"reglog\", \"under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in tqdm(strats):\n",
    "    oversample = SMOTE()\n",
    "    D = X[\"base\"]\n",
    "    X_sample, y_sample = oversample.fit_resample(D, ytrain)\n",
    "    \n",
    "    X[\"X_over\"] = X_sample\n",
    "    X[\"y_over\"] = y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, reglog_optimizer, \"reglog\", \"over\")\n",
    "get_scores(strats, \"reglog\", \"over\")\n",
    "optimization_report(strats, \"reglog\", \"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, reglog_optimizer, \"reglog\", \"over\", scoring=\"roc_auc_ovo\")\n",
    "get_scores(strats, \"reglog\", \"over\")\n",
    "optimization_report(strats, \"reglog\", \"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, svm_optimizer, \"svm\", \"over\")\n",
    "get_scores(strats, \"svm\", \"over\")\n",
    "optimization_report(strats, \"svm\", \"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_strats(strats, bnb_optimizer, \"bnb\", \"over\")\n",
    "get_scores(strats, \"bnb\", \"over\")\n",
    "optimization_report(strats, \"bnb\", \"over\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_max = None\n",
    "model_max = None\n",
    "score_max = 0\n",
    "\n",
    "for X in strats:\n",
    "    for model in [\"reglog\", \"svm\", \"rf\", \"bnb\"]:\n",
    "        score = (X[f\"scores_{model}\"][\"f1_score\"] + X[f\"scores_{model}\"][\"auc_roc\"]) / 2\n",
    "        \n",
    "        if score > score_max:\n",
    "            score_max = score\n",
    "            strat_max = X\n",
    "            model_max = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pres_test(fname):\n",
    "    alltxts = []\n",
    "    s = codecs.open(fname, 'r', 'utf-8')  # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if (len(txt)) < 5:\n",
    "            break\n",
    "\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*>(.*)\", \"\\\\1\", txt)\n",
    "        alltxts.append(txt)\n",
    "\n",
    "    return np.array(alltxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.test.utf8\"\n",
    "testtxts = load_pres_test(fname)\n",
    "testtxts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Xval_lem\" not in globals():\n",
    "    Xval_lem = lemmatize_data(testtxts)\n",
    "\n",
    "Xval_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = np.concatenate((Xtrain_lem.reshape(-1, ), Xtest_lem.reshape(-1, )), axis=0)\n",
    "y_lem = np.concatenate((np.array(ytrain).reshape(-1, ), np.array(ytest).reshape(-1, )), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem_trans = strat_max[\"vectorizer\"].transform(X_lem)\n",
    "strat_max[model_max].fit(X_lem_trans, y_lem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Max (f1_score + auc_roc) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval_tran = strat_max[\"vectorizer\"].transform(Xval_lem)\n",
    "y_hat = strat_max[model_max].predict(Xval_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"push_2\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(np.where(y_hat == -1, \"M\", \"C\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
